{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1단계 : 유동인구 특성 클러스터링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동코드 추출\n",
    "gs_dong_code = pd.read_excel(data_path +'offer/*****.xlsx',\n",
    "                             sheet_name='참고)구_행정동코드', skiprows=1)\n",
    "seoul_code_list = gs_dong_code[gs_dong_code.시명=='서울특별시'][['행정동명', '행정동코드']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동별 면적 추출\n",
    "area = pd.read_excel(data_path +'untact service related features.xlsx', usecols=['행정동', '면적(m^2)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동코드-면적\n",
    "code_area = pd.merge(seoul_code_list, area, left_on='행정동명', right_on='행정동')[['행정동코드','면적(m^2)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동별 유동인구 데이터\n",
    "pop_data = pd.DataFrame()\n",
    "\n",
    "for i in range(19,21):\n",
    "    for j in range(2,6):\n",
    "        temp = pd.read_csv(data_path+'data.seoul.go.kr/LOCAL_PEOPLE_DONG_20'+str(i)+'0'+str(j)+'.csv', index_col=False)\n",
    "        temp.set_index('기준일ID', inplace=True)\n",
    "        temp.index = pd.to_datetime(temp.index, format='%Y%m%d')\n",
    "        \n",
    "        pop_data = pd.concat([pop_data, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정리\n",
    "# 노원구, 중구 데이터만 추출\n",
    "pop_data = pop_data[pop_data.행정동코드.isin(seoul_code_list.행정동코드)]\n",
    "\n",
    "# 연령대별로 정리, 성별 유동인구 합치기\n",
    "col_name = ['0', '10', '15', '20', '25', '30', '35', '40', '45', '50', '55', '60', '65', '70+']\n",
    "m_peo = pop_data.iloc[:,3:17]\n",
    "f_peo = pop_data.iloc[:,17:]\n",
    "m_peo.columns = col_name\n",
    "f_peo.columns = col_name\n",
    "a_peo = m_peo + f_peo\n",
    "\n",
    "pop_data_tmp = pd.concat([pop_data.iloc[:,:2], a_peo], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  70세 이상 인구 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_result = pop_data_tmp.sort_values(by = ['행정동코드', '기준일ID', '시간대구분'])\n",
    "pop_result = pop_result.drop(['70+'], axis=1)\n",
    "pop_result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  '행정동-일별'로 평면화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행정동-특정 날짜에 대해 유동인구 데이터는 시간대별, 연령대별로 2차원 형태\n",
    "# 시간대, 연령대 - (24, 13) -> (312,) 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cols = ['행정동코드', '기준일ID']\n",
    "num_cols = [i for i in range(0,312)]\n",
    "cols = idx_cols+num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_list = []\n",
    "\n",
    "for i in tqdm(range(0,len(pop_result),24)):\n",
    "    code_date = pop_result.iloc[i,[2,0]]\n",
    "    pop_values = pop_result.iloc[i:i+24,3:].values.reshape(-1)\n",
    "    temp_row = np.concatenate([code_date, pop_values])\n",
    "    reshape_list.append(temp_row)\n",
    "\n",
    "final = pd.DataFrame(reshape_list, columns=['행정동코드', '기준일ID']+[i for i in range(312)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(data_path+'checkpoints.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "final = pd.read_csv(data_path+'checkpoints.csv')\n",
    "final['기준일ID'] = pd.to_datetime(final.기준일ID, format='%Y-%m-%d')\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 행정동에 대해 19/20년도 요일 평균 유동인구 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 형태\n",
    "      소공동 월요일 : 0~10세0001 / 0~10세0102 ... / 65~70세2324\n",
    "      소공동 화요일 : 0~10세0001 / 0~10세0102 ... / 65~70세2324\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_19 = final[final.기준일ID < '2020/02/01']\n",
    "X_20 = final[final.기준일ID >= '2020/02/01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_19_week = pd.DataFrame(columns=np.concatenate([['code', 'weekday'], X_19.columns[2:].values]))\n",
    "X_20_week = pd.DataFrame(columns=np.concatenate([['code', 'weekday'], X_20.columns[2:].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final.행정동코드.unique()) * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in final.행정동코드.unique():\n",
    "    # 19년도\n",
    "    temp = X_19[X_19.행정동코드 == code].drop('행정동코드', axis=1)\n",
    "    temp['weekday'] = temp.기준일ID.dt.dayofweek\n",
    "    week_temp = temp.groupby('weekday').mean().reset_index()\n",
    "    week_temp['code'] = code\n",
    "    X_19_week = X_19_week.append(week_temp)\n",
    "    \n",
    "    # 20년도\n",
    "    temp = X_20[X_20.행정동코드 == code].drop('행정동코드', axis=1)\n",
    "    temp['weekday'] = temp.기준일ID.dt.dayofweek\n",
    "    week_temp = temp.groupby('weekday').mean().reset_index()\n",
    "    week_temp['code'] = code\n",
    "    X_20_week = X_20_week.append(week_temp)\n",
    "    \n",
    "X_19_week.reset_index(drop=True, inplace=True)\n",
    "X_20_week.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_19_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_20_weekzhead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유동인구 데이터를 0과 1사이로 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScaled_pop(week):\n",
    "    result_scale = pd.DataFrame(columns=week.columns)\n",
    "    \n",
    "    for i in range(len(week)):\n",
    "        temp_values = week.iloc[i,2:].values.reshape(-1,1)\n",
    "        scaler = MinMaxScaler()\n",
    "        temp_scale = scaler.fit_transform(temp_values)\n",
    "        \n",
    "        row_scale = np.concatenate([week.iloc[i,:2].values, temp_scale.reshape(-1)])\n",
    "        result_scale.loc[i, :]= row_scale\n",
    "    \n",
    "    return result_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_19_week_scale = getScaled_pop(X_19_week)\n",
    "X_20_week_scale = getScaled_pop(X_20_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행정동 면적을 사용하여 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유동인구 데이터를 0과 1사이로 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 유동인구 데이터에 면적 column 추가\n",
    "def getScaled_area(week, code_area):\n",
    "    temp = pd.merge(week, code_area, left_on='code', right_on='행정동코드')\n",
    "\n",
    "    # 유동인구 / 해당 동 면적\n",
    "    for i in range(2,314):\n",
    "        temp[temp.columns[i]]= temp.iloc[:,i]/temp.loc[:,'면적(m^2)']\n",
    "    temp.drop(['행정동코드', '면적(m^2)'], axis=1, inplace=True)\n",
    "\n",
    "    temp_values = temp.iloc[:,2:]\n",
    "    scaler = MinMaxScaler()\n",
    "    temp_scale = scaler.fit_transform(temp_values)\n",
    "\n",
    "    result_scale = pd.concat([temp.iloc[:,:2],pd.DataFrame(temp_scale, columns=temp.columns[2:])], axis=1)\n",
    "    \n",
    "    return result_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_19_week_scale = getScaled_area(X_19_week, code_area)\n",
    "X_20_week_scale = getScaled_area(X_20_week, code_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_19_week_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_20_week_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 요일별 행정동 유동인구 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '1-# 각 행정동에 대해 19/20년도 요일 평균 유동인구 계산' 참고\n",
    "# X_19_week, X_20_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday\n",
    "import calendar\n",
    "\n",
    "col_name = ['0', '10', '15', '20', '25', '30', '35', '40', '45', '50', '55', '60', '65']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeekPlot(dongname, year, colorbar):\n",
    "    if year == 19 : \n",
    "        data = X_19_week\n",
    "    else :\n",
    "        data = X_20_week\n",
    "        \n",
    "    vmin = int(round(data.iloc[:,2:].min().min()))\n",
    "    vmax = int(round(data.iloc[:,2:].max().max()))\n",
    "    \n",
    "    code = seoul_code_list[seoul_code_list.행정동명 == dongname].행정동코드.values[0]\n",
    "    temp = data[data.code == code]\n",
    "    \n",
    "    \n",
    "    n = 7\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    for i in range(0,n):\n",
    "        \n",
    "        # 24x13 행렬도 쪼갬 \n",
    "        \n",
    "        pick = pd.DataFrame(temp.iloc[i,2:].to_numpy().reshape(24,13))\n",
    "        pick.index.name = '시간대구분'\n",
    "        pick.columns = col_name\n",
    "        output= pick.T.astype(float) # type error : not numeric?\n",
    "        \n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        \n",
    "        if colorbar:\n",
    "            plt.pcolor(output, cmap='YlGnBu', vmin=vmin, vmax=vmax)  # colorbar 통일 \n",
    "        else :\n",
    "            plt.pcolor(output, cmap='YlGnBu')\n",
    "        plt.xticks(np.arange(0.5, len(output.columns), 1), output.columns)\n",
    "        plt.yticks(np.arange(0.5, len(output.index), 1), output.index)\n",
    "        plt.title(dongname+'_'+str(year)+'_'+calendar.day_name[i])\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getWeekPlot('소공동', 19, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 차원축소(TSNE) 및 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  연도별 TSNE, DBSCAN, KMEANS 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_19_train = X_19_week_scale.iloc[:,2:].to_numpy()\n",
    "x_20_train = X_20_week_scale.iloc[:,2:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate를 일반적 범위인 10~1000까지 살펴가면 최적값 찾음\n",
    "for i in range(10,1000, 1):\n",
    "    model = TSNE(learning_rate=i, random_state=0, n_jobs=-1)\n",
    "    transformed = model.fit_transform(x_20_train)\n",
    "\n",
    "    plt.scatter(transformed[:,0], transformed[:,1], cmap='prism')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltTSNE_DBSCAN(x, lr, eps, min_s, rand):\n",
    "    model = TSNE(learning_rate=lr, random_state=rand)\n",
    "    transformed = model.fit_transform(x)\n",
    "\n",
    "    model = DBSCAN(eps=eps, min_samples=min_s) #metric='euclidean'\n",
    "    predict = model.fit(transformed)\n",
    "    y_pred = predict.labels_\n",
    "        \n",
    "    # Assign result to df\n",
    "    dataset = pd.DataFrame({'Column1':transformed[:,0],'Column2':transformed[:,1]})\n",
    "    dataset['cluster_num'] = pd.Series(y_pred)\n",
    "\n",
    "    plt.scatter(dataset.Column1, dataset.Column2, c=dataset['cluster_num'], cmap=plt.cm.RdYlGn)\n",
    "    plt.show()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltTSNE_KMEANS(x, lr, k, rand, rand_k):\n",
    "    model = TSNE(learning_rate=lr, random_state=rand)\n",
    "    transformed = model.fit_transform(x)\n",
    "    \n",
    "    model = KMeans(init=\"k-means++\", n_clusters=k, random_state=rand_k)\n",
    "    model.fit(transformed)\n",
    "    y_pred = model.labels_\n",
    "    \n",
    "    # Assign result to df\n",
    "    dataset = pd.DataFrame({'Column1':transformed[:,0],'Column2':transformed[:,1]})\n",
    "    dataset['cluster_num'] = pd.Series(y_pred)\n",
    "\n",
    "    plt.scatter(dataset.Column1, dataset.Column2, c=dataset['cluster_num'], cmap=plt.cm.RdYlGn)\n",
    "    plt.show()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20년 : DBSCAN의 최적 eps와 min_s는 각각 3, 10임.\n",
    "# 19년 : DBSCAN의 최적 eps와 min_s는 각각 3, 10임.\n",
    "## eps 범위 : 0 ~ 무한대\n",
    "## min_s 범위 : 2 ~ (case-1)\n",
    "\n",
    "temp_set = pltTSNE_DBSCAN(x_20_train, 30, 3, 10, 0)\n",
    "print(temp_set.cluster_num.value_counts())\n",
    "#pltTSNE_DBSCAN(x_19_train, 30, 3, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_set = pltTSNE_KMEANS(x_20_train, 30, 5, 0, 0)\n",
    "print(temp_set.cluster_num.value_counts())\n",
    "#pltTSNE_KMEANS(x_19_train, 200, 7, 20, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tNSE_2020_final = TSNE(learning_rate=30, random_state=0)\n",
    "transformed_tSNE = model_tNSE_2020_final.fit_transform(x_20_train)\n",
    "\n",
    "model_DBSCAN_2020_final = DBSCAN(eps=3, min_samples=10) #metric='euclidean'\n",
    "predict_2020_final = model_DBSCAN_2020_final.fit(transformed_tSNE)\n",
    "cluster_labels_2020_final = predict_2020_final.labels_\n",
    "\n",
    "for i in range(len(cluster_labels_2020_final)):\n",
    "    cluster = cluster_labels_2020_final[i]\n",
    "    dong = seoul_code_list[['행정동명','행정동코드']].set_index('행정동코드').loc[X_20_week_scale.iloc[i]['code']][0]\n",
    "    weekday = X_20_week_scale.iloc[i]['weekday']\n",
    "    \n",
    "    print(dong, '_', str(weekday), '  ', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tNSE_2020_final = TSNE(learning_rate=30, random_state=0)\n",
    "transformed_tSNE = model_tNSE_2020_final.fit_transform(x_20_train)\n",
    "\n",
    "model_KMEANS_2020_final = KMeans(init=\"k-means++\", n_clusters=5, random_state=0)\n",
    "predict_2020_final = model_KMEANS_2020_final.fit(transformed_tSNE)\n",
    "cluster_labels_2020_final = predict_2020_final.labels_\n",
    "\n",
    "for i in range(len(cluster_labels_2020_final)):\n",
    "    cluster = cluster_labels_2020_final[i]\n",
    "    dong = seoul_code_list[['행정동명','행정동코드']].set_index('행정동코드').loc[X_20_week_scale.iloc[i]['code']][0]\n",
    "    weekday = X_20_week_scale.iloc[i]['weekday']\n",
    "    \n",
    "    print(dong, '_', str(weekday), '  ', cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  실루엣 스코어 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_silhouette_DBSCAN(X_features, lr, eps, min_s, rand): \n",
    "    \n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import MeanShift\n",
    "    from sklearn.cluster import estimate_bandwidth\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "    \n",
    "    model = TSNE(learning_rate=lr, random_state=rand)\n",
    "    transformed = model.fit_transform(X_features)\n",
    "\n",
    "    model = DBSCAN(eps=eps, min_samples=min_s) #metric='euclidean'\n",
    "    predict = model.fit(transformed)\n",
    "    cluster_labels = predict.labels_\n",
    "\n",
    "    plt.plot(figsize=(4, 4), nrows=1)\n",
    "    \n",
    "    #print(cluster_labels)\n",
    "    \n",
    "    no_clu = np.where(cluster_labels != -1)\n",
    "    \n",
    "    X_features = X_features[no_clu]\n",
    "    cluster_labels = cluster_labels[no_clu]\n",
    "    #print(cluster_labels)\n",
    "\n",
    "    sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "    sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "    n_cluster = len(np.unique(cluster_labels))\n",
    "    sil_std = float(pd.DataFrame(data=[sil_values,cluster_labels]).transpose().rename(columns={0:'sil', 1:'cluster'})\\\n",
    "            .groupby('cluster').mean().std())\n",
    "\n",
    "    y_lower = 10\n",
    "    plt.title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "              'Ave. Silhouette Score :' + str(round(sil_avg,3))+'\\n' \\\n",
    "              'Std. Silhouette Score :' + str(round(sil_std,3)))\n",
    "    \n",
    "    plt.xlabel(\"The silhouette coefficient values\")\n",
    "    plt.ylabel(\"Cluster label\")\n",
    "    plt.xlim([-0.1, 1])\n",
    "    plt.ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "    plt.yticks([])  # Clear the yaxis labels / ticks\n",
    "    plt.xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "    for i in range(n_cluster):\n",
    "        ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "        ith_cluster_sil_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "        plt.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                            facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    plt.axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(learning_rate=30, random_state=0)\n",
    "transformed = model.fit_transform(x_20_train)\n",
    "\n",
    "model = DBSCAN(eps=3, min_samples=10) #metric='euclidean'\n",
    "predict = model.fit(transformed)\n",
    "cluster_labels = predict.labels_\n",
    "\n",
    "len(np.unique(cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first : 2020 noReduction')\n",
    "print('second : 2020 reduction')\n",
    "visualize_silhouette_DBSCAN(x_20_train, 30, 3, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 시각화한 함수 작성\n",
    "def visualize_silhouette_KMEANS(cluster_lists, X_features, lr, rand, rand_k): \n",
    "    \n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "    \n",
    "    model = TSNE(learning_rate=lr, random_state=rand)\n",
    "    transformed = model.fit_transform(X_features)    \n",
    "    \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산.\n",
    "        \n",
    "        model = KMeans(init=\"k-means++\", n_clusters=n_cluster, random_state=rand_k)\n",
    "        model.fit(transformed)\n",
    "        cluster_labels = model.labels_\n",
    "    \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        sil_std = float(pd.DataFrame(data=[sil_values,cluster_labels]).transpose().rename(columns={0:'sil', 1:'cluster'})\\\n",
    "                        .groupby('cluster').mean().std())\n",
    "        \n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Ave. Silhouette Score :' + str(round(sil_avg,3))+'\\n' \\\n",
    "                          'Std. Silhouette Score :' + str(round(sil_std,3)))\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])  # * 10\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "            \n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "            \n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_19_week_01scale = X_19_week.iloc[:,2:]\n",
    "max_val = X_19_week.iloc[:,2:].max(axis=1)\n",
    "\n",
    "for i in range(len(X_19_week_01scale)):\n",
    "    X_19_week_01scale.iloc[i] = X_19_week_01scale.iloc[i] / max_val[0]\n",
    "\n",
    "X_19_week_01scale['code'] = X_19_week['code']\n",
    "X_19_week_01scale['weekday'] = X_19_week['weekday']\n",
    "\n",
    "\n",
    "X_20_week_01scale = X_20_week.iloc[:,2:]\n",
    "max_val = X_20_week.iloc[:,2:].max(axis=1)\n",
    "\n",
    "for i in range(len(X_20_week_01scale)):\n",
    "    X_20_week_01scale.iloc[i] = X_20_week_01scale.iloc[i] / max_val[0]\n",
    "\n",
    "X_20_week_01scale['code'] = X_20_week['code']\n",
    "X_20_week_01scale['weekday'] = X_20_week['weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_19_train_01scale = X_19_week_01scale.iloc[:,:-2].to_numpy()\n",
    "x_20_train_01scale = X_20_week_01scale.iloc[:,:-2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr 10 ~ 1000\n",
    "lr_list = [390, 400, 410]\n",
    "#range(99,601,50)\n",
    "\n",
    "for i in lr_list:\n",
    "    print(i)\n",
    "    model = TSNE(learning_rate=i, random_state=0, n_jobs=-1)\n",
    "    transformed = model.fit_transform(x_20_train_01scale)\n",
    "\n",
    "    plt.scatter(transformed[:,0], transformed[:,1], cmap='prism')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x_20_train_01scale\n",
    "\n",
    "eps = 3.3\n",
    "min_s = 10\n",
    "lr = 400\n",
    "\n",
    "pltTSNE_DBSCAN(data, lr, eps, min_s, 0)\n",
    "\n",
    "\n",
    "\n",
    "visualize_silhouette_DBSCAN(data, lr, eps, min_s, 0)\n",
    "\n",
    "\n",
    "\n",
    "model_tNSE_2020_final = TSNE(learning_rate=lr, random_state=0)\n",
    "transformed_tSNE = model_tNSE_2020_final.fit_transform(data)\n",
    "\n",
    "model_DBSCAN_2020_final = DBSCAN(eps=eps, min_samples=min_s) #metric='euclidean'\n",
    "predict_2020_final = model_DBSCAN_2020_final.fit(transformed_tSNE)\n",
    "cluster_labels_2020_final = predict_2020_final.labels_\n",
    "\n",
    "for i in range(len(cluster_labels_2020_final)):\n",
    "    cluster = cluster_labels_2020_final[i]\n",
    "    dong = seoul_code_list[['행정동명','행정동코드']].set_index('행정동코드').loc[X_20_week_01scale.iloc[i]['code']][0]\n",
    "    weekday = X_20_week_01scale.iloc[i]['weekday']\n",
    "    \n",
    "    print(dong, '_', str(weekday), '  ', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x_19_train_01scale\n",
    "\n",
    "eps = 2\n",
    "min_s = 10\n",
    "lr = 400\n",
    "\n",
    "pltTSNE_DBSCAN(data, lr, eps, min_s, 0)\n",
    "\n",
    "\n",
    "\n",
    "visualize_silhouette_DBSCAN(data, lr, eps, min_s, 0)\n",
    "\n",
    "\n",
    "\n",
    "model_tNSE_2020_final = TSNE(learning_rate=lr, random_state=0)\n",
    "transformed_tSNE = model_tNSE_2020_final.fit_transform(data)\n",
    "\n",
    "model_DBSCAN_2020_final = DBSCAN(eps=eps, min_samples=min_s) #metric='euclidean'\n",
    "predict_2020_final = model_DBSCAN_2020_final.fit(transformed_tSNE)\n",
    "cluster_labels_2020_final = predict_2020_final.labels_\n",
    "\n",
    "for i in range(len(cluster_labels_2020_final)):\n",
    "    cluster = cluster_labels_2020_final[i]\n",
    "    dong = seoul_code_list[['행정동명','행정동코드']].set_index('행정동코드').loc[X_20_week_01scale.iloc[i]['code']][0]\n",
    "    weekday = X_20_week_01scale.iloc[i]['weekday']\n",
    "    \n",
    "    print(dong, '_', str(weekday), '  ', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tNSE_2020_final = TSNE(learning_rate=lr, random_state=0)\n",
    "transformed_tSNE = model_tNSE_2020_final.fit_transform(x_20_train_01scale)\n",
    "\n",
    "model_DBSCAN_2020_final = DBSCAN(eps=eps, min_samples=min_s) #metric='euclidean'\n",
    "predict_2020_final = model_DBSCAN_2020_final.fit(transformed_tSNE)\n",
    "cluster_labels_2020_final = predict_2020_final.labels_\n",
    "\n",
    "for i in range(len(cluster_labels_2020_final)):\n",
    "    cluster = cluster_labels_2020_final[i]\n",
    "    dong = seoul_code_list[['행정동명','행정동코드']].set_index('행정동코드').loc[X_20_week_01scale.iloc[i]['code']][0]\n",
    "    weekday = X_20_week_01scale.iloc[i]['weekday']\n",
    "    \n",
    "    print(dong, '_', str(weekday), '  ', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
